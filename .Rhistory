library(stats)
print(paste("Pearson correlation: ",cor.test(WT_per,prop_CD,method = "pearson")))
print(paste("Spearman correlation: ",cor.test(WT_per,prop_CD,method = "spearman")))
print(paste("Kendall correlation: ",cor.test(WT_per,prop_CD,method = "kendall")))
cor.test(WT_per,prop_CD,method = "pearson")
res = cor.test(WT_per,prop_CD,method = "pearson")
library(stats)
print(paste("Pearson correlation: ",cor.test(WT_per,prop_CD,method = "pearson")$statistic))
print(paste("Spearman correlation: ",cor.test(WT_per,prop_CD,method = "spearman")$statistic))
print(paste("Kendall correlation: ",cor.test(WT_per,prop_CD,method = "kendall")$statistic))
library(stats)
print(paste("Pearson correlation: ",cor.test(WT_per,prop_CD,method = "pearson")$statistic))
print(paste("Spearman correlation: ",cor.test(WT_per,prop_CD,method = "spearman")$statistic))
print(paste("Kendall correlation: ",cor.test(WT_per,prop_CD,method = "kendall")$statistic))
cor.test(WT_per,prop_CD,method = "spearman")
View(res)
library(stats)
print(paste("Pearson correlation: ",cor.test(WT_per,prop_CD,method = "pearson")$estimate))
print(paste("Spearman correlation: ",cor.test(WT_per,prop_CD,method = "spearman")$estimate))
print(paste("Kendall correlation: ",cor.test(WT_per,prop_CD,method = "kendall")$estimate))
knitr::opts_chunk$set(echo = TRUE)
weather = read.delim("./STCDAY.txt")
weather = weather[-c(1,12417:12427),] #remove unwanted information
library(sqldf)
library(dplyr)
library(plotly)
library(ggplot2)
# Read the data, select year month, day, AAT, ARH from the table
data <- sqldf("
SELECT year, month, day, avg_air_temp as AAT, avg_rel_hum as ARH
FROM weather
")
data$AAT = as.numeric(data$AAT)
data$ARH = as.numeric(data$ARH)
## Review NA Rows
# For AAT
rows1 = grep(TRUE, is.na(data$AAT))
slice(data, rows1)
data[rows1,]
# For ARH
rows2 = grep(TRUE, is.na(data$ARH))
slice(data, rows2)
data[rows2,]
#
data2 = data
data2$AAT[rows1] = sapply(rows1,function(x)mean(data2$AAT[!is.na(data2$AAT)&(data2$month==data2$month[x])]))
data2$ARH[rows2] = sapply(rows2,function(x)mean(data2$ARH[!is.na(data2$ARH)&(data2$month==data2$month[x])]))
heat_index = function(T,RH){
HI = -42.379 + 2.04901523*T + 10.14333127*RH - .22475541*T*RH - .00683783*T*T - .05481717*RH*RH + .00122874*T*T*RH + .00085282*T*RH*RH - .00000199*T*T*RH*RH
return(HI)
}
data2$HI = sapply(1:nrow(data2),function(x)(heat_index(data2$AAT[x],data2$ARH[x])
data2$HI = sapply(1:nrow(data2),function(x)(heat_index(data2$AAT[x],data2$ARH[x])))
View(data2)
View(data)
quantile(data2$HI,0.85)
CMI_TRH<-read.csv("CMI_TRH.csv")
View(CMI_TRH)
heat_index = function(T,RH){
HI = -42.379 + 2.04901523*T + 10.14333127*RH - .22475541*T*RH - .00683783*T*T - .05481717*RH*RH + .00122874*T*T*RH + .00085282*T*RH*RH - .00000199*T*T*RH*RH
return(HI)
}
CMI_TRH2$HI = sapply(1:nrow(CMI_TRH),function(x)(heat_index(CMI_TRH$avg_air_temp_f[x],CMI_TRH$avg_rel_hum[x])))
CMI_TRH$HI = sapply(1:nrow(CMI_TRH),function(x)(heat_index(CMI_TRH$avg_air_temp_f[x],CMI_TRH$avg_rel_hum[x])))
quantile(CMI_TRH$HI,0.85)
install.packages('weathermetrics')
CMI_TRH$HI = weathermetrics::heat.index.algorithm(CMI_TRH$avg_air_temp_f,CMI_TRH$avg_air_temp_c)
CMI_TRH$HI = weathermetrics::heat.index(t = CMI_TRH$avg_air_temp_f,rh =CMI_TRH$avg_air_temp_c)
quantile(CMI_TRH$HI,0.85)
CMI_TRH$HI = weathermetrics::heat.index(t = CMI_TRH$avg_air_temp_f,rh =CMI_TRH$avg_rel_hum)
quantile(CMI_TRH$HI,0.85)
quantile(CMI_TRH$HI,0.85)
CMI_TRH$HI = weathermetrics::heat.index(t = CMI_TRH$avg_air_temp_f,rh =CMI_TRH$avg_rel_hum)
CMI_TRH$HI = weathermetrics::heat.index(t = CMI_TRH$avg_air_temp_f,rh =CMI_TRH$avg_rel_hum)
quantile(CMI_TRH$HI,0.85)
quantile(CMI_TRH$HI,0.85)
quantile(CMI_TRH$HI,0.85)
quantile(CMI_TRH$HI,0.85)
is.na(CMI_TRH$HI)
sum(is.na(CMI_TRH$HI))
quantile(CMI_TRH$HI[!is.na(CMI_TRH)],0.85)
quantile(CMI_TRH$HI[!is.na(CMI_TRH$HI)],0.85)
data2$HI = weathermetrics::heat.index(t=data2$AAT,rh=data2$ARH)
quantile(data2$HI[!is.na(data2$HI)],0.85)
# Mean Intensity
data_summer$period<- ifelse(data_summer$year<2005,"Before","After")
knitr::opts_chunk$set(echo = TRUE)
weather = read.delim("./STCDAY.txt")
weather = weather[-c(1,12417:12427),] #remove unwanted information
library(sqldf)
library(dplyr)
library(plotly)
library(ggplot2)
# Read the data, select year month, day, AAT, ARH from the table
data <- sqldf("
SELECT year, month, day, avg_air_temp as AAT, avg_rel_hum as ARH
FROM weather
")
data$AAT = as.numeric(data$AAT)
data$ARH = as.numeric(data$ARH)
## Review NA Rows
# For AAT
rows1 = grep(TRUE, is.na(data$AAT))
slice(data, rows1)
data[rows1,]
# For ARH
rows2 = grep(TRUE, is.na(data$ARH))
slice(data, rows2)
data[rows2,]
#
data2 = data
data2$AAT[rows1] = sapply(rows1,function(x)mean(data2$AAT[!is.na(data2$AAT)&(data2$month==data2$month[x])]))
data2$ARH[rows2] = sapply(rows2,function(x)mean(data2$ARH[!is.na(data2$ARH)&(data2$month==data2$month[x])]))
# Build new data frame with no
# NAs and column AAT, ART, month, data
data_Xna <- data2 %>% mutate(
date_string = paste(year, month, day, sep="-"),
date = as.Date(date_string)
)
glimpse(data_Xna)
time_series_AAT <- plot_ly(data_Xna, type = 'scatter', mode = 'lines') %>%
add_trace(x = ~date, y = ~AAT, line = list(color = "grey")) %>%
layout(showlegend = F, title = "AAT",
yaxis = list(title="Degrees Farenheit"))
time_series_AAT
time_series_ARH <- plot_ly(data_Xna, type = 'scatter', mode = 'lines') %>%
add_trace(x = ~date, y = ~ARH, line = list(color = "grey")) %>%
layout(showlegend = F, title = "ARH",
yaxis = list(title="Percentage"))
time_series_ARH
ggplot(data = data_Xna, aes(x = date, y = AAT)) +
geom_line(color = "dark orange") +
labs(title = "AAT") +
ylab("Average Temperature (F)") +
xlab("Date")
ggplot(data = data_Xna, aes(x = date, y = ARH)) +
geom_line(color = "dark orange") +
labs(title = "ARH") +
ylab("Average Humidity (F)") +
xlab("Date")
data_summer = data_Xna[data_Xna$month == '7'|data_Xna$month == '8',] #filter the months
ggplot(data_Xna,aes(x=AAT))+geom_histogram()
ggplot(data_summer,aes(x=AAT))+geom_histogram()
qqnorm(data_summer$AAT)
qqline(data_summer$AAT)
shapiro.test(data_summer$AAT)
ks.test(data_summer$AAT,"pnorm",mean(data_summer$AAT),sd(data_summer$AAT))
library(goftest)
cvm.test(data_summer$AAT,"pnorm",mean(data_summer$AAT),sd(data_summer$AAT))
ad.test(data_summer$AAT,"pnorm",mean(data_summer$AAT),sd(data_summer$AAT))
# Mean Intensity
data_summer$period<- ifelse(data_summer$year<2005,"Before","After")
period1<-data_summer %>% filter(period =='Before')
period2<-data_summer%>% filter (period == 'After')
shapiro.test(period1$AAT)
shapiro.test(period2$AAT)
t.test(period1$AAT,period2$AAT)
CMI_TRH<-read.csv("CMI_TRH.csv")
CMI_TRH$HI = weathermetrics::heat.index(t = CMI_TRH$avg_air_temp_f,rh =CMI_TRH$avg_rel_hum)
quantile(CMI_TRH$HI[!is.na(CMI_TRH$HI)],0.85)
wilcox.test(period1$AAT,period2$AAT)
data(dietswap)
library(microbiome)
data("dietswap")
source("./Dropbox/Research/PhylogeneticMetricLearning/Normalization/code/Algorithm.R")
X = abundances(dietswap)
res = cn(X)
X = as.matrix(X)
res = cn(X)
X
View(X)
X = as.data.frame(X)
cn(X)
d = nrow(X)
v = CStat(X)
I0.1 = which(v>0.8)
X0 = X[I0.1,]
v0 = replicate(3,CStat(X0[sample(1:nrow(X0),0.5*nrow(X0)),]))
data("atlas1006")
X = abundances(atlas1006)
d = nrow(X)
> v = CStat(X)
v = CStat(X)
I0.1 = which(v>0.8)
devtools::load_all("Desktop/RSimNorm/")
devtools::load_all()
data("gut_cn")
cn(count_table = gut_cn)
devtools::load_all("Desktop/RSimNorm/")
cn(count_table = gut_cn)
devtools::load_all("Desktop/RSimNorm/")
res = cn(count_table = gut_cn)
library(biomformat)
library(stringr)
library(ape)
library(phyloseq)
library(MicrobiomeStat)
library(ggVennDiagram)
library(edgeR)
library(dada2)
library(microbiome)
##data preprocessing
filepath <- "../data/thai/"
folders<-list.files(path = filepath)
i=1
filep<-paste(filepath,"/","reference-hit.biom", sep = "")
x = read_biom(filep)
library(biomformat)
library(stringr)
library(ape)
library(phyloseq)
library(MicrobiomeStat)
library(ggVennDiagram)
library(edgeR)
library(dada2)
library(microbiome)
##data preprocessing
filepath <- "../data/thai/"
folders<-list.files(path = filepath)
i=1
filep<-paste(filepath,"/","reference-hit.biom", sep = "")
x = read_biom(filep)
filepath <- "./Dropbox/Research/PhylogeneticMetricLearning/Normalization/code/data/thai/"
folders<-list.files(path = filepath)
i=1
filep<-paste(filepath,"/","reference-hit.biom", sep = "")
x = read_biom(filep)
#seqtab<-as(biom_data(x), "matrix")
#seqtab<-t(seqtab)
treep<-paste(filepath,"/","insertion_tree.relabelled.tre", sep = "")
treefile = readChar(treep,file.info(treep)$size)
str_count(treefile, pattern = '; ')
treefile2 = gsub('; ','|',treefile)
tree = read.tree(text=treefile2)
nalength=is.na(tree$edge.length)
nonzerolength=tree$edge.length!=0
tree$edge.length[nalength]=sample(tree$edge.length[(!nalength)&nonzerolength], sum(nalength))
sum(tree$edge.length==0 & tree$edge[,2]<=length(tree$tip.label))
meta = read.delim(paste(filepath,"/","12080_20210508-071948.txt", sep = ""))
samplenames <- sapply(x$columns, function(y){y$id})
meta <- meta[meta$sample_name %in% samplenames,]
otu <- sapply(x$rows, function(y){y$id})
drop_tips <- tree$tip.label[!(tree$tip.label %in% otu)]
tree <- ape::drop.tip(tree,drop_tips) %>% ape::as.phylo()
P <- sapply(x$data, function(y,subsamplenames){y[subsamplenames]}, subsamplenames = meta$sample_name)
colnames(P) <- otu
P = t(P)
P = P[rowSums(P)>0,]
rownames(meta) = meta$sample_name
taxonomy = read.csv("Dropbox/Research/PhylogeneticMetricLearning/Normalization/code/data/taxonomy.csv",row.names=1)
OTU = otu_table(P,taxa_are_rows=T) # matrix
META = sample_data(meta) # data frame
PHYLO = phy_tree(tree) # tree (list)
TAXA = tax_table(as.matrix(taxonomy))
physeq = phyloseq(OTU,TAXA,META, PHYLO)
cn(physeq)
pseq = subset_samples(physeq,(ethnicity == "Karen"))
t.normalized(pseq,tax_level = "Genus",main_var = sample_group)
devtools::load_all()
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = sample_group)
TAX = phyloseq::tax_table(physeq)
META = phyloseq::sample_data(physeq)
OTU = phyloseq::otu_table(X.cn,taxa_are_rows = T)
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = sample_group)
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = sample_group)
View(meta)
t.normalized(pseq,tax_level = "Genus",main_var = "sample_group")
Y = meta[,'sample_group']
length(Y)
meta = phyloseq::sample_data(physeq)
Y = meta[,'sample_group']
length(Y)
Y = as.vector(Y)
length(Y)
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = sample_group)
t.normalized(pseq,tax_level = "Genus",main_var = "sample_group")
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = "sample_group")
devtools::load_all(path='Desktop/RSimNorm/')
t.normalized(pseq,tax_level = "Genus",main_var = "sample_group")
setwd("./Desktop/RSimNorm/")
load_all()
library(devtools)
load_all()
test()
install.packages('test_hat')
test()
install.packages("testthat")
install.packages("testthat")
load_all()
test()
load_all
load_all()
test_file("tests/testthat/test-RSimNorm.R")
load_all()
test_file("tests/testthat/test-RSimNorm.R")
load_all()
test_file("tests/testthat/test-RSimNorm.R")
usethis::use_vignette("RSimNorm")
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
data("Karen")
# Phyloseq
pseq = Karen
# Count and meta matrix
count = microbiome::abundances(pseq)
meta = data.frame(phyloseq::sample_data(pseq))
out1 = RSimNorm(pseq)
out2 = RSimNorm(count_table = count)
t.out1 = t.normalized(pseq, main_var = "sample_group")
View(meta)
Y = meta[,'sample_group']
yY
Y
count_table = NULL
physeq = pseq
lib_cut = 0
tax_level = NULL
meta = NULL
main_var = 'sample_group'
method = "BH"
alpha = 0.05
eta = 0
lib_cut = 0
bootstrap_num = 3
# 1. data preprocessing
if(is.null(count_table)){
if(!is.null(physeq)){
count_table = microbiome::abundances(physeq)
meta = phyloseq::sample_data(physeq)
X = data_preprocess(count_table, lib_cut)
}else{
stop('Must have count data.')
}
}else{
X = data_preprocess(count_table, lib_cut)
meta = meta
}
meta = data.frame(meta)
if(any(is.na(X))) {
stop('The OTU/ASV table contains NAs! Please remove!\n')
}
X.cn = RSimNorm(count_table = X, eta, lib_cut, bootstrap_num)$P
if(!is.null(tax_level)){
TAX = phyloseq::tax_table(physeq)
META = phyloseq::sample_data(physeq)
OTU = phyloseq::otu_table(X.cn,taxa_are_rows = T)
physeq1 = phyloseq::phyloseq(OTU,TAXA,META)
physeq.agg = microbiome::aggregate_taxa(physeq1,tax_level)
X = microbiome::abundances(physeq.agg)
}else{
X = X.cn
}
Y = meta[,main_var]
if(length(unique(Y)) > 2) {
stop('Main varaible contains too many categories. Only two are allowed for t-test.')
}
if(any(is.na(Y))){
stop('Main varaible contains NAs! Please remove!\n')
}
if(ncol(X)!=length(Y)){
stop('Main varaible has different size with samples.')
}
d = nrow(X)
data = data.frame(cbind(t(X),Y))
colnames(data)[ncol(data)] = 'Y'
t_p <- sapply(1:d, function(i)t.test(data[, i] ~ Y, data = data)$p.value)
View(data)
data$Y
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 2] ~ Y, data = data)
t.test(data[, 3] ~ Y, data = data)
Y
t.test(data[, 4] ~ Y, data = data)
t.test(data[, 4] ~ Y, data = data)
unique(Y)
data[data$Y == 'Karen1st',1]
data[data$Y == 'KarenThai',1]
data[data$Y == 'Karen1st',1]
t.test(data[, 4] ~ as.factor(Y), data = data)
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 1] ~ Y, data = data)
t.test(data[, 1] ~ Y, data = data)
View(data)
t.test(rownames(X)[1] ~ Y, data = data)
t.test(data[,1] ~ Y, data = data)
t.test(data[which(Y=='KarenThai'),1],data[which(Y=='Karen1st'),1])
t.test(data[,1] ~ 1, data = data)
d = nrow(X)
data = data.frame(cbind(t(X),Y))
colnames(data)[ncol(data)] = 'Y'
t_p <- sapply(1:d, function(i)t.test(as.numeric(data[, i]) ~ Y, data = data)$p.value)
d = nrow(X)
data = data.frame(cbind(t(X),Y))
View(data)
type(data)
class(data[,1])
as.numeric(data[,1])
type(X.cn[,1])
class(X.cn[,1])
load_all()
t.out1 = t.normalized(pseq, main_var = "sample_group")
t.out1
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group", tax_level = NULL,
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
t.out2 = t.normalized(count_table = count, meta = meta,
main_var = "sample_group")
t.out2 %>%
datatable(caption = "t_results") %>%
formatRound(col_name[-1], digits = 2)
install.packages("DT")
library(RSimNorm)
library(DT)
library(RSimNorm)
library(DT)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
t.out2 %>%
datatable(caption = "t_results") %>%
formatRound(col_name[-1], digits = 2)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
t.out2 %>%
datatable(caption = "t_results") %>%
formatRound(colnames(out2), digits = 2)
library(RSimNorm)
library(DT)
datatable(data, options = list(), class = "display",
callback = JS("return table;"), rownames, colnames, container,
caption = NULL, filter = c("none", "bottom", "top"), escape = TRUE,
style = "auto", width = NULL, height = NULL, elementId = NULL,
fillContainer = getOption("DT.fillContainer", NULL),
autoHideNavigation = getOption("DT.autoHideNavigation", NULL),
selection = c("multiple", "single", "none"), extensions = list(),
plugins = NULL, editable = FALSE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
data_table(t.out2)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
datatable(t.out2)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
t.out3 = t.normalized(pseq, main_var = "sample_group", tax_level = "genus",
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
load_all()
library(RSimNorm)
t.out3 = t.normalized(pseq, main_var = "sample_group", tax_level = "genus",
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
t.out3 = t.normalized(pseq, main_var = "sample_group", tax_level = "Genus",
meta = NULL, method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
datatable(t.out3)
load_all()
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
corr.out1 = corr.normalized(pseq, main_var = "age", tax_level = NULL,
meta = NULL, type = "pearson", method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
datatable(corr.out1)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
corr.out2 = corr.normalized(count_table = count, main_var = "age", tax_level = NULL,
meta = meta, type = "pearson", method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
datatable(corr.out2)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, comment = NA,
fig.width = 6.25, fig.height = 5)
corr.out3 = corr.normalized(pseq, main_var = "age", tax_level = "Genus",
meta = NULL, type = "pearson", method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
datatable(corr.out2)
corr.out3 = corr.normalized(pseq, main_var = "age", tax_level = "Genus",
meta = NULL, type = "pearson", method = "BH", alpha = 0.05,
eta = 0, lib_cut = 0, bootstrap_num = 3)
datatable(corr.out3)
devtools::build_rmd("vignettes/RSimNorm.Rmd")
devtools::build_rmd("vignettes/RSimNorm.Rmd")
devtools::build_rmd("vignettes/RSimNorm.Rmd")
